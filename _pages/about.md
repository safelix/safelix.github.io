---
layout: about
permalink: /

title: # about # title in navbar
#subtitle: <a href='https://tue.ellis.eu/'>ELLIS Insitute</a>, <a href='https://is.mpg.de/'>Max Planck Institute for Intelligent Systems</a>, <a href='https://ethz.ch/'>ETH Zürich</a>

profile:
  align: right
  image: me.jpg #prof_pic.jpg
  image_circular: false # crops the image to make it circular
  #more_info: >
  #  <p>555 your office number</p>
  #  <p>123 your address street</p>
  #  <p>Your City, State 12345</p>

news: true # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page
---

I am a doctoral fellow within the [Max Planck ETH Center for Learning Systems (CLS)](https://learning-systems.org/) under the supervision of [Antonio Orvieto](http://orvi.altervista.org/) and [Thomas Hofmann](https://da.inf.ethz.ch/people/ThomasHofmann/). As such, I am a member of both the [Data Analytics Lab](https://da.inf.ethz.ch/) at [ETH Zürich](https://ethz.ch/) and the [Deep Models and Optimization Group](https://tue.ellis.eu/research-groups/deep-models-and-optimization) at the newly established [ELLIS Institute](https://tue.ellis.eu/) and the [MPI-IS](https://is.mpg.de/) in Tübingen.


After obtaining my bachelor's and master's degrees in Computer Science from ETH Zürich, I pursued research internships with Thomas Hofmann in Zürich, [Nicolas Flammarion](https://people.epfl.ch/nicolas.flammarion) at EPFL Lausanne, and Antonio Orvieto in Tübingen.

I am generally fascinated by the **learning dynamics of neural networks** and the interaction of parameterization, initialization, objective, and optimization in deep learning. In particular, I'm interested in potentially **self-supervised** methods for **long-range** modeling and **feature learning** of sequential data. To that end, I'm currently investigating fundamental aspects of **linear recurrent neural networks**.
